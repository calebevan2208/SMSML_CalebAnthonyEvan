# SMSML_CalebAnthony

Project ini adalah implementasi end-to-end Machine Learning pipeline untuk prediksi churn nasabah kartu kredit. Ini mencakup data ingestion, preprocessing, EDA, model training (TensorFlow/Keras), experiment tracking (MLflow), monitoring (Prometheus + Grafana), dan CI with GitHub Actions.

---

## ğŸ“‚ Struktur Project (ringkas)
- `Eksperimen_SML_CalebAnthony/` â€” Eksperimen, EDA, dan preprocessing
- `Membangun_model/` â€” Training, tuning, dan model artifacts
- `Monitoring_dan_Logging/` â€” Prometheus exporter, Docker Compose, Grafana provisioning
- `Workflow-CI/` & `.github/workflows/` â€” CI workflows and MLProject entry points
- `mlruns/` & `artifacts/` â€” MLflow runs & logged artifacts

---

## ğŸ“ Project tree (comprehensive)
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ model_output/
â”‚       â”œâ”€â”€ model.h5
â”‚       â”œâ”€â”€ scaler.pkl
â”‚       â””â”€â”€ loss_curve.png
â”œâ”€â”€ Eksperimen_SML_CalebAnthonyEvan/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ churn_raw/
â”‚   â”‚   â”‚   â””â”€â”€ data.csv
â”‚   â”‚   â””â”€â”€ churn_preprocessing/
â”‚   â”‚       â””â”€â”€ clean_data.csv
â”‚   â”œâ”€â”€ automate_CalebAnthony.py
â”‚   â”œâ”€â”€ Eksperimen_CalebAnthony.ipynb
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ Membangun_model/
â”‚   â”œâ”€â”€ modelling.py
â”‚   â”œâ”€â”€ modelling_tuning.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ DagsHub.txt
â”‚   â”œâ”€â”€ screenshoot_dashboard.png
â”‚   â”œâ”€â”€ screenshoot_artifacts.png
â”‚   â””â”€â”€ churn_preprocessing/
â”‚       â””â”€â”€ clean_data.csv
â”œâ”€â”€ Monitoring_dan_Logging/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ Dockerfile.exporter
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ 2.prometheus.yml
â”‚   â”œâ”€â”€ 3.prometheus_exporter.py
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”‚   â””â”€â”€ simple-dashboard.json
â”‚   â”‚   â””â”€â”€ provisioning/
â”‚   â”‚       â”œâ”€â”€ dashboards/
â”‚   â”‚       â”‚   â””â”€â”€ dashboard.yaml
â”‚   â”‚       â””â”€â”€ datasources/
â”‚   â”œâ”€â”€ 4.bukti monitoring Prometheus/
â”‚   â”‚   â”œâ”€â”€ monitoring_prometheus_http_requests_total.png
â”‚   â”‚   â””â”€â”€ monitoring_process_cpu_seconds_total.png
â”‚   â””â”€â”€ 5.bukti monitoring Grafana/
â”‚       â”œâ”€â”€ grafana_dashboard.png
â”‚       â””â”€â”€ monitoring_prometheus_http_request_duration_seconds_bucket.png
â”œâ”€â”€ Workflow-CI/
â”‚   â”œâ”€â”€ MLProject/
â”‚   â”‚   â”œâ”€â”€ MLproject
â”‚   â”‚   â”œâ”€â”€ modelling.py
â”‚   â”‚   â””â”€â”€ conda.yaml
â”‚   â””â”€â”€ ci.yml
â”œâ”€â”€ mlruns/
â”‚   â”œâ”€â”€ 0/
â”‚   â””â”€â”€ 400292112877238592/
â”‚       â””â”€â”€ 89aa66a3f2c948299613c59bf73b2349/
â”‚           â”œâ”€â”€ meta.yaml
â”‚           â”œâ”€â”€ artifacts/
â”‚           â”‚   â””â”€â”€ custom_artifacts/
â”‚           â”‚       â””â”€â”€ loss_curve.png
â”‚           â””â”€â”€ metrics/ (see MLflow)
â”œâ”€â”€ charts/
â”‚   â”œâ”€â”€ learning_curve.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ pr_curve.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â””â”€â”€ lift_curve.png
â””â”€â”€ other files
    â”œâ”€â”€ pr_curve.png
    â””â”€â”€ learning_curve.png
```

---

## âœ… Recent additions (Dec 2025)
- Added sample datasets:
  - `Eksperimen_SML_CalebAnthonyEvan/preprocessing/churn_raw/data.csv`
  - `Eksperimen_SML_CalebAnthonyEvan/preprocessing/churn_preprocessing/clean_data.csv`
- Added many visualization images (learning curve, ROC, confusion matrix) and Grafana/Prometheus screenshots under `Monitoring_dan_Logging/`.
- Monitoring stack and provisioning (Prometheus + Grafana + exporter) with `docker-compose` and dashboard JSONs.
- CI: lightweight GitHub Actions workflow at `.github/workflows/ci.yml` with optional `workflow_dispatch` for manual runs.

---

## ğŸš€ Quick start
1. Install Python deps:

```bash
python -m pip install -r Membangun_model/requirements.txt
```

2. Run training (baseline):

```bash
python Membangun_model/modelling.py
```

3. Run monitoring stack (Docker Compose):

```bash
docker compose -f Monitoring_dan_Logging/docker-compose.yml up --build -d
# Grafana: http://localhost:3000 (default admin:admin â€” change after first login)
```

4. Run exporter locally:

```bash
python -m pip install -r Monitoring_dan_Logging/requirements.txt
python Monitoring_dan_Logging/3.prometheus_exporter.py
```

---

## ğŸ’¡ Notes & recommendations
- Large binary/data files (PNGs, CSVs) were added to the repo recently. To avoid repository bloat, consider enabling Git LFS:

```bash
git lfs install
git lfs track "*.png" "*.csv"
# Commit .gitattributes
# Optionally rewrite history: git lfs migrate import --include="*.png,*.csv"
```

- MLflow: scripts are resilient â€” they will fall back to a local `mlruns/` folder if a remote tracking server is unavailable.

---

If you'd like, I can also enable Git LFS and migrate the current large files into LFS for you.
